[{"authors":["Jie-Ren"],"categories":null,"content":"Jie is collaborating with us on large-scale GPU-based linear system solvers.\n","date":1660521600,"expirydate":-62135596800,"kind":"term","lang":"en","lastmod":1660521600,"objectID":"f8e812c0035dbedbea67c36012073d09","permalink":"https://luomai.github.io/author/jie-ren/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/author/jie-ren/","section":"authors","summary":"Jie is collaborating with us on large-scale GPU-based linear system solvers.","tags":null,"title":"Jie Ren","type":"authors"},{"authors":["Xiulong-Yuan"],"categories":null,"content":"Xiulong is collaborating with us on large-scale graph learning systems.\n","date":-62135596800,"expirydate":-62135596800,"kind":"term","lang":"en","lastmod":-62135596800,"objectID":"55b5cd5454e5408ed0414f92d767d709","permalink":"https://luomai.github.io/author/xiulong-yuan/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/author/xiulong-yuan/","section":"authors","summary":"Xiulong is collaborating with us on large-scale graph learning systems.","tags":null,"title":"Xiulong Yuan","type":"authors"},{"authors":["Zeyuan-Tan"],"categories":null,"content":"Zeyuan was a MScR student working on an open-sourced distributed graph learning system: Quiver. He has joined a leading start-up company Kumo.ai after graduation.\n","date":-62135596800,"expirydate":-62135596800,"kind":"term","lang":"en","lastmod":-62135596800,"objectID":"3b020c596d71e3cc9302c5da93ecb7ca","permalink":"https://luomai.github.io/author/zeyuan-tan/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/author/zeyuan-tan/","section":"authors","summary":"Zeyuan was a MScR student working on an open-sourced distributed graph learning system: Quiver. He has joined a leading start-up company Kumo.ai after graduation.","tags":null,"title":"Zeyuan Tan","type":"authors"},{"authors":["Chijun-Sima"],"categories":null,"content":" Chijun Sima homepage.\n","date":1667260800,"expirydate":-62135596800,"kind":"term","lang":"en","lastmod":1667260800,"objectID":"efa841db90e49dcb035e58a044376ffb","permalink":"https://luomai.github.io/author/chijun-sima/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/author/chijun-sima/","section":"authors","summary":"Chijun Sima homepage.","tags":null,"title":"Chijun Sima","type":"authors"},{"authors":["Yao-Fu"],"categories":null,"content":" Yao Fu homepage.\n","date":1667260800,"expirydate":-62135596800,"kind":"term","lang":"en","lastmod":1667260800,"objectID":"1c71ea3d26c0b0a01eaa178d034b647b","permalink":"https://luomai.github.io/author/yao-fu/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/author/yao-fu/","section":"authors","summary":"Yao Fu homepage.","tags":null,"title":"Yao Fu","type":"authors"},{"authors":["Man-Kit-Sit"],"categories":null,"content":" Man-Kit Sit homepage.\n","date":1667260800,"expirydate":-62135596800,"kind":"term","lang":"en","lastmod":1667260800,"objectID":"fc23037b1605cd04a6e0178f37fbbd1d","permalink":"https://luomai.github.io/author/man-kit-sit/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/author/man-kit-sit/","section":"authors","summary":"Man-Kit Sit homepage.","tags":null,"title":"Man-Kit Sit","type":"authors"},{"authors":["Leyang-Xue"],"categories":null,"content":" Leyang Xue homepage\n","date":-62135596800,"expirydate":-62135596800,"kind":"term","lang":"en","lastmod":-62135596800,"objectID":"913c54416bc7c1ba7ae0f64c1568c7a9","permalink":"https://luomai.github.io/author/leyang-xue/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/author/leyang-xue/","section":"authors","summary":"Leyang Xue homepage","tags":null,"title":"Leyang Xue","type":"authors"},{"authors":["Congejie-He"],"categories":null,"content":"Congjie is designing future scalable systems for machine learning and quantum simulation.\n","date":-62135596800,"expirydate":-62135596800,"kind":"term","lang":"en","lastmod":-62135596800,"objectID":"cc0767cd28edfd47e2f2f826d6c2c59d","permalink":"https://luomai.github.io/author/congjie-he/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/author/congjie-he/","section":"authors","summary":"Congjie is designing future scalable systems for machine learning and quantum simulation.","tags":null,"title":"Congjie He","type":"authors"},{"authors":["admin"],"categories":null,"content":"I am an Assistant Professor (UK Lecturer) in the School of Informatics at the University of Edinburgh. I am a member of the Institute of Computing Systems Architecture where I am leading the Edinburgh System-X Group. Our research group designs scalable, adaptive and efficient system software to support emerging data-centric applications and utilise novel computing platforms.\nBefore coming to Edinburgh, I was a research associate (2018 - 2020) at the Imperial College London working with Peter Pietzuch. I earned my PhD degree from Imperial College London under the supervision of Paolo Costa and Alexander L. Wolf. My PhD was supported by a Google Fellowship in Cloud Computing. During my PhD study, I was a research intern (2015, 2016) and a visiting researcher (2017) at Microsoft Research.\n I am always looking for self-motivated PhD, MScR and Post-doc. Drop me an email with your CV if you are interested. I am a member of the supervisor teams in the CDT in NLP and the CDT in Biomedical AI. Check here for how to apply.   ","date":1667260800,"expirydate":-62135596800,"kind":"term","lang":"en","lastmod":1667260800,"objectID":"2525497d367e79493fd32b198b28f040","permalink":"https://luomai.github.io/author/luo-mai/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/author/luo-mai/","section":"authors","summary":"I am an Assistant Professor (UK Lecturer) in the School of Informatics at the University of Edinburgh. I am a member of the Institute of Computing Systems Architecture where I am leading the Edinburgh System-X Group.","tags":null,"title":"Luo Mai","type":"authors"},{"authors":["Jiawei-Liu"],"categories":null,"content":"Jiawei visited my group from 2020 - 2021, working on high-performance computer vision systems. His project has led to a popular open-source library: HyperPose, and a paper accepted to ACM Multimedia 2021. Jiawei is pursuing his PhD at the University of Illinois at Urbana Champaign (UIUC).\n","date":1628985600,"expirydate":-62135596800,"kind":"term","lang":"en","lastmod":1628985600,"objectID":"ce97fd581d7e2429725dc1930d3a115e","permalink":"https://luomai.github.io/author/jiawei-liu/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/author/jiawei-liu/","section":"authors","summary":"Jiawei visited my group from 2020 - 2021, working on high-performance computer vision systems. His project has led to a popular open-source library: HyperPose, and a paper accepted to ACM Multimedia 2021.","tags":null,"title":"Jiawei Liu","type":"authors"},{"authors":["Andrei-Octavian-Brabete"],"categories":null,"content":"Andrei did his MEng project \u0026ldquo;Kungfu: A Novel Distributed Training System for TensorFlow using Flexible Synchronisation\u0026rdquo; at Imperial College London in 2019. His project received a Distinguished Project Award as well as a Departmental Price for Excellence. There are only 3 students who can receive these two awards at a time in 2019. Andrei joined G-Research after graduation.\n","date":1606780800,"expirydate":-62135596800,"kind":"term","lang":"en","lastmod":1606780800,"objectID":"789243ef38d81e10fc09b683a5129c67","permalink":"https://luomai.github.io/author/andrei-octavian-brabete/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/author/andrei-octavian-brabete/","section":"authors","summary":"Andrei did his MEng project \u0026ldquo;Kungfu: A Novel Distributed Training System for TensorFlow using Flexible Synchronisation\u0026rdquo; at Imperial College London in 2019. His project received a Distinguished Project Award as well as a Departmental Price for Excellence.","tags":null,"title":"Andrei-Octavian Brabete","type":"authors"},{"authors":["Marcel-Wagenlander"],"categories":null,"content":"Marcel did a research project \u0026ldquo;Large-scale training of the Google BERT model\u0026rdquo; at Imperial College London in 2020. His project has led to a paper \u0026ldquo;Spotnik: Designing Distributed Machine Learning for Transient Cloud Resources\u0026rdquo; accepted by a leading system workshop: USENIX HotCloud 2020. Marcel started as a PhD student at Imperial College London afterwards.\n","date":1606780800,"expirydate":-62135596800,"kind":"term","lang":"en","lastmod":1606780800,"objectID":"b906b9ad100240ef5914119e4e019158","permalink":"https://luomai.github.io/author/marcel-wagenlander/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/author/marcel-wagenlander/","section":"authors","summary":"Marcel did a research project \u0026ldquo;Large-scale training of the Google BERT model\u0026rdquo; at Imperial College London in 2020. His project has led to a paper \u0026ldquo;Spotnik: Designing Distributed Machine Learning for Transient Cloud Resources\u0026rdquo; accepted by a leading system workshop: USENIX HotCloud 2020.","tags":null,"title":"Marcel Wagenlander","type":"authors"},{"authors":["Guanqi-Zhan"],"categories":null,"content":"Guanqi visited my group in 2019 and acted as a key developer for TensorLayer. His research work has been accepted to leading ML venues such as NeurIPS. Guanqi is pursuing his PhD in machine learning and computer vision at the University of Oxford.\n","date":-62135596800,"expirydate":-62135596800,"kind":"term","lang":"en","lastmod":-62135596800,"objectID":"bdbdceb8c2eccbcedaf9af5b01fa5383","permalink":"https://luomai.github.io/author/guanqi-zhan/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/author/guanqi-zhan/","section":"authors","summary":"Guanqi visited my group in 2019 and acted as a key developer for TensorLayer. His research work has been accepted to leading ML venues such as NeurIPS. Guanqi is pursuing his PhD in machine learning and computer vision at the University of Oxford.","tags":null,"title":"Guanqi Zhan","type":"authors"},{"authors":["Ioan-Budea"],"categories":null,"content":"Ioan did his MEng project \u0026ldquo;TensorBow: Supporting Small-Batch Training in TensorFlow\u0026rdquo; at Imperial College London in 2019. His project received a Distinguished Project Award as well as a Departmental Price for Excellence. There are only 3 students who can receive these two awards at a time in 2019. Ioan joined Facebook after graduation.\n","date":-62135596800,"expirydate":-62135596800,"kind":"term","lang":"en","lastmod":-62135596800,"objectID":"3bb2df6388766214ff822961b1d87ac3","permalink":"https://luomai.github.io/author/ioan-budea/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/author/ioan-budea/","section":"authors","summary":"Ioan did his MEng project \u0026ldquo;TensorBow: Supporting Small-Batch Training in TensorFlow\u0026rdquo; at Imperial College London in 2019. His project received a Distinguished Project Award as well as a Departmental Price for Excellence.","tags":null,"title":"Ioan Budea","type":"authors"},{"authors":["Chijun Sima","Yao Fu","Man-Kit Sit","Liyi Guo","Xuri Gong","Feng Lin","Junyu Wu","Yongsheng Li","Haidong Rong","Pierre-Louis Aublin","Luo Mai"],"categories":null,"content":"","date":1667260800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1667260800,"objectID":"9f72ce46778e193faf5f89ec0d7d5c20","permalink":"https://luomai.github.io/publication/2022-osdi-ekko/","publishdate":"2022-11-01T00:00:00Z","relpermalink":"/publication/2022-osdi-ekko/","section":"publication","summary":"Deep Learning Recommender Systems (DLRSs) need to update models at low latency, thus promptly serving new users and content. Existing DLRSs, however, fail to do so. They train/validate models offline and broadcast entire models to global inference clusters. They thus incur significant model update latency (e.g. dozens of minutes), which adversely affects Service-Level Objectives (SLOs).\nThis paper describes Ekko, a novel DLRS that enables low-latency model updates. Its design idea is to allow model updates to be immediately disseminated to all inference clusters, thus bypassing long-latency model checkpoint, validation and broadcast. To realise this idea, we first design an efficient peer-to-peer model update dissemination algorithm. This algorithm exploits the sparsity and temporal locality in updating DLRS models to improve the throughput and latency of updating models. Further, Ekko has a model update scheduler that can prioritise, over busy networks, the sending of model updates that can largely affect SLOs. Finally, Ekko has an inference model state manager which monitors the SLOs of inference models and rollbacks the models if SLO-detrimental biased updates are detected. Evaluation results show that Ekko is orders of magnitude faster than state-of-the-art DLRS systems. Ekko has been deployed in production for more than one year, serves over a billion users daily and reduces the model update latency compared to state-of-the-art systems from dozens of minutes to 2.4 seconds.","tags":["Machine Learning Systems"],"title":"Ekko: A Large-Scale Deep Learning Recommender System with Low-Latency Model Update","type":"publication"},{"authors":[],"categories":[],"content":"Our paper \u0026ldquo;A Theoretical Understanding of Gradient Bias in Meta-Reinforcement Learning\u0026rdquo; is accepted by NeurIPS 2022. This paper is based on our recently released system for differential optimisation: TorchOpt. TorchOpt is accepted as a paper by the 14th International Workshop for Optimization for Machine Learning (OPT) co-located with NeurIPS 2022.\n","date":1662813337,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1662813337,"objectID":"5d05bae71f26c1e05b52e455c3b62576","permalink":"https://luomai.github.io/post/22-settling-neurips/","publishdate":"2022-09-10T13:35:37+01:00","relpermalink":"/post/22-settling-neurips/","section":"post","summary":"Our paper \u0026ldquo;A Theoretical Understanding of Gradient Bias in Meta-Reinforcement Learning\u0026rdquo; is accepted by NeurIPS 2022. This paper is based on our recently released system for differential optimisation: TorchOpt. TorchOpt is accepted as a paper by the 14th International Workshop for Optimization for Machine Learning (OPT) co-located with NeurIPS 2022.","tags":[],"title":"TorchOpt and papers are accepted to NeurIPS 2022","type":"post"},{"authors":["Bo Liu","Xidong Feng","Jie Ren","Luo Mai","Rui Zhu","Haifeng Zhang","Jun Wang","Yaodong Yang"],"categories":null,"content":"","date":1660521600,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1660521600,"objectID":"0922d3edb8db4ccd6e5c2dc493c6f963","permalink":"https://luomai.github.io/publication/2022-neurips-settling/","publishdate":"2022-08-15T00:00:00Z","relpermalink":"/publication/2022-neurips-settling/","section":"publication","summary":"Gradient-based Meta-RL (GMRL) refers to methods that maintain two-level optimisation procedures wherein the outer-loop meta-learner guides the inner-loop gradient-based reinforcement learner to achieve fast adaptations. In this paper, we develop a unified framework that describes variations of GMRL algorithms and points out that existing stochastic meta-gradient estimators adopted by GMRL are actually \textbf{biased}. Such meta-gradient bias comes from two sources: 1) the compositional bias incurred by the two-level problem structure, which has an upper bound of (KαKσ̂ In|τ|−0.5) \u001bmph{w.r.t.} inner-loop update step K, learning rate α, estimate variance σ̂ 2In and sample size |τ|, and 2) the multi-step Hessian estimation bias Δ̂ H due to the use of autodiff, which has a polynomial impact ((K−1)(Δ̂ H)K−1) on the meta-gradient bias. We study tabular MDPs empirically and offer quantitative evidence that testifies our theoretical findings on existing stochastic meta-gradient estimators. Furthermore, we conduct experiments on Iterated Prisoner's Dilemma and Atari games to show how other methods such as off-policy learning and low-bias estimator can help fix the gradient bias for GMRL algorithms in general.","tags":["Machine Learning Systems"],"title":"A Theoretical Understanding of Gradient Bias in Meta-Reinforcement Learning","type":"publication"},{"authors":["Jie Ren","Xidong Feng","Bo Liu","Xuehai Pan","Luo Mai","Yaodong Yang"],"categories":null,"content":"","date":1660521600,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1660521600,"objectID":"d8dd4381a2e6f2919edb9b05dfa24f44","permalink":"https://luomai.github.io/publication/2022-neurips-torchopt/","publishdate":"2022-08-15T00:00:00Z","relpermalink":"/publication/2022-neurips-torchopt/","section":"publication","summary":"Recent years have witnessed the booming of various differentiable optimization algorithms. These algorithms exhibit different execution patterns, and their execution needs massive computational resources that go beyond a single CPU and GPU. Existing differentiable optimization libraries, however, cannot support efficient algorithm development and multi-CPU/GPU execution, making the development of differentiable optimization algorithms often cumbersome and expensive. This paper introduces TorchOpt, a PyTorch-based efficient library for differentiable optimization. TorchOpt provides a unified and expressive bi-level optimization programming abstraction. This abstraction allows users to efficiently declare and analyze various differentiable optimization programs with explicit gradients, implicit gradients, and zero-order gradients. TorchOpt further provides a high-performance distributed execution runtime. This runtime can fully parallelize computation-intensive differentiation operations (e.g. tensor tree flatten) on CPUs/GPUs and automatically distribute computation to distributed devices. Experimental results show that TorchOpt outperforms state-of-the-art libraries by 7x on an 8-GPU server.","tags":["Machine Learning Systems"],"title":"TorchOpt: An Efficient library for Differentiable Optimization","type":"publication"},{"authors":["Jie Ren","Wenteng Liang*","Ran Yan","Luo Mai","Shiwen Liu","Xiao Liu"],"categories":null,"content":"","date":1660089600,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1660089600,"objectID":"20da1d22f97dcbf9095e52e3c0078653","permalink":"https://luomai.github.io/publication/2022-eccv-megba/","publishdate":"2022-08-10T00:00:00Z","relpermalink":"/publication/2022-eccv-megba/","section":"publication","summary":"Large-scale Bundle Adjustment (BA) requires massive memory and computation resources which are difficult to be fulfilled by existing BA libraries. In this paper, we propose MegBA, a GPU-based distributed BA library. MegBA can provide massive aggregated memory by automatically partitioning large BA problems, and assigning the solvers of sub-problems to parallel nodes. The parallel solvers adopt distributed Precondition Conjugate Gradient and distributed Schur Elimination, so that an effective solution, which can match the precision of those computed by a single node, can be efficiently computed. To accelerate BA computation, we implement end-to-end BA computation using high-performance primitives available on commodity GPUs. MegBA exposes easy-to-use APIs that are compatible with existing popular BA libraries. Experiments show that MegBA can significantly outperform state-of-the-art BA libraries: Ceres (41.45×), RootBA (64.576×) and DeepLM (6.769×) in several large-scale BA benchmarks. The code of MegBA is available at: https://github.com/MegviiRobot/MegBA.","tags":["Machine Learning Systems"],"title":"MegBA: A GPU-Based Distributed Library for Large-Scale Bundle Adjustment","type":"publication"},{"authors":[],"categories":[],"content":"Our Paper \u0026ldquo;MegBA: A GPU-Based Distributed Library for Large-Scale Bundle Adjustment\u0026rdquo; is accepted by ECCV 2022. ECCV is considered to be one of the top conferences in computer vision, alongside CVPR and ICCV.\n","date":1657456537,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1657456537,"objectID":"ad8e8e6c026bdfc6ea429e84f68831e7","permalink":"https://luomai.github.io/post/22-megba-eccv/","publishdate":"2022-07-10T13:35:37+01:00","relpermalink":"/post/22-megba-eccv/","section":"post","summary":"Our Paper \u0026ldquo;MegBA: A GPU-Based Distributed Library for Large-Scale Bundle Adjustment\u0026rdquo; is accepted by ECCV 2022. ECCV is considered to be one of the top conferences in computer vision, alongside CVPR and ICCV.","tags":[],"title":"MegBA in ECCV 2022","type":"post"},{"authors":[],"categories":[],"content":"Our Paper \u0026ldquo;Ekko: A Large-Scale Deep Learning Recommender System with Low-Latency Model Update\u0026rdquo; is accepted by USENIX Symposium on Operating Systems Design and Implementation (OSDI) 2022. OSDI is a highly selective flagship conference in computer science, especially on the topic of computer systems. This year, there were only 2 accepted papers from UK institutes.\nOSDI brings together professionals from academic and industrial backgrounds in what has become a premier forum for discussing the design, implementation, and implications of systems software. The symposium emphasizes innovative research as well as quantified or insightful experiences in systems design and implementation.\n","date":1647606937,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1647606937,"objectID":"4fb1f746a8ea70cad215d31e0922d323","permalink":"https://luomai.github.io/post/22-ekko-osdi/","publishdate":"2022-03-18T13:35:37+01:00","relpermalink":"/post/22-ekko-osdi/","section":"post","summary":"Our Paper \u0026ldquo;Ekko: A Large-Scale Deep Learning Recommender System with Low-Latency Model Update\u0026rdquo; is accepted by USENIX Symposium on Operating Systems Design and Implementation (OSDI) 2022. OSDI is a highly selective flagship conference in computer science, especially on the topic of computer systems.","tags":[],"title":"Ekko in OSDI 2022","type":"post"},{"authors":["Le Xu","Shivaram Venkataraman","Indranil Gupta","Luo Mai","Rahul Potharaju"],"categories":null,"content":"","date":1638316800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1638316800,"objectID":"2b078c2eb38852aa4a7e6a7d45f62723","permalink":"https://luomai.github.io/publication/2021-nsdi-cameo/","publishdate":"2021-12-01T00:00:00Z","relpermalink":"/publication/2021-nsdi-cameo/","section":"publication","summary":"Resource provisioning in multi-tenant stream processing systems faces the dual challenges of keeping resource utilization high (without over-provisioning), and ensuring performance isolation. In our common production use cases, where stream-ing workloads have to meet latency targets and avoid breach-ing service-level agreements, existing solutions are in capable of handling the wide variability of user needs. Our framework called Cameo uses fine-grained stream processing (inspired by actor computation models), and is able to provide high resource utilization while meeting latency targets. Cameo dynamically calculates and propagates priorities of events based on user latency targets and query semantics.  Experiments on Microsoft Azure show that compared to state-of-the-art,the Cameo framework: i) reduces query latency by 2.7× in single tenant settings, ii) reduces query latency by 4.6× in multi-tenant scenarios, and iii) weathers transient spikes of workload.","tags":["Big Data Systems"],"title":"Move Fast and Meet Deadlines: Fine-grained Real-time Stream Processing with Cameo","type":"publication"},{"authors":[],"categories":[],"content":" Quiver is a distributed graph learning library for PyTorch Geometric (PyG). Its excellent performance and scalability has made it quickly become the recommended distributed library for PyG.\n","date":1635684355,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1635684355,"objectID":"e13a049bb363357618cf62627ec75868","permalink":"https://luomai.github.io/post/21-quiver-opensource/","publishdate":"2021-10-31T13:45:55+01:00","relpermalink":"/post/21-quiver-opensource/","section":"post","summary":"Quiver is a distributed graph learning library for PyTorch Geometric (PyG). Its excellent performance and scalability has made it quickly become the recommended distributed library for PyG.","tags":[],"title":"Quiver is open-sourced","type":"post"},{"authors":null,"categories":null,"content":"The primary motivation for the Quiver project is to make it easy to take a PyG script and scale it across many GPUs and CPUs. A typical scenario is: Quiver users can leverage the high-level APIs and rich examples of PyG to design graph learning algorithms, and then use Quiver to scale PyG algorithms to run at large scale. To make such scaling efficient, Quiver has several features:\n  High performance: Quiver enables GPUs to be efficiently used in accelerating performance-critical graph learning tasks: graph sampling, feature collection and data-parallel training. Quiver thus can out-perform PyG and DGL even with a single GPU, especially when processing large-scale datasets and models.\n  High scalability: Quiver can achieve (super) linear scalability in distributed graph learning. This is contributed by Quiver\u0026rsquo;s novel communication-efficient data/processor management techniques and effective usage of fast networking technologies (e.g., NVLink and RDMA).\n  Easy to use: Quiver requires only a few new lines of code in existing PyG programs and it has no external heavy dependency. Quiver is thus easy to be adopted by PyG users and integrated into production clusters.\n  ","date":1635638400,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1635638400,"objectID":"0f69ae98615c8408e0a602a28ecbd81f","permalink":"https://luomai.github.io/project/quiver/","publishdate":"2021-10-31T00:00:00Z","relpermalink":"/project/quiver/","section":"project","summary":"Fast and Easy Distributed Graph Learning for PyTorch [![GitHub stars](https://img.shields.io/github/stars/quiver-team/torch-quiver.svg?style=social\u0026label=Star\u0026maxAge=2592000)](https://github.com/quiver-team/torch-quiver/stargazers/)","tags":null,"title":"Quiver","type":"project"},{"authors":[],"categories":[],"content":"HyperPose and RLzoo are both accepted to the Open-source Software Competition in ACM Multimedia 2021. ACM Multimedia is the worldwide premier conference and a key world event to display scientific achievements and innovative industrial products in the multimedia field.\n","date":1629030937,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1629030937,"objectID":"97dcbc469510982cab706f9aaf34b984","permalink":"https://luomai.github.io/post/21-hyperpose-rlzoo-accept-news/","publishdate":"2021-08-15T13:35:37+01:00","relpermalink":"/post/21-hyperpose-rlzoo-accept-news/","section":"post","summary":"HyperPose and RLzoo are both accepted to the Open-source Software Competition in ACM Multimedia 2021. ACM Multimedia is the worldwide premier conference and a key world event to display scientific achievements and innovative industrial products in the multimedia field.","tags":[],"title":"HyperPose and RLzoo in open-source software competition","type":"post"},{"authors":["Zihan Ding","Tianyang Yu","Yanhua Huang","Hongming Zhang","Guo Li","Quancheng Guo","Luo Mai","Hao Dong"],"categories":null,"content":"","date":1628985600,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1628985600,"objectID":"e1efa02d25fa9d46e59e2ed681f15cf4","permalink":"https://luomai.github.io/publication/2021-multimedia-rlzoo/","publishdate":"2020-08-15T00:00:00Z","relpermalink":"/publication/2021-multimedia-rlzoo/","section":"publication","summary":"Many multimedia developers are exploring for adopting Deep Re- inforcement Learning (DRL) techniques in their applications. They however often find such an adoption challenging. Existing DRL libraries provide poor support for prototyping DRL agents (i.e., models), customising the agents, and comparing the performance of DRL agents. As a result, the developers often report low efficiency in developing DRL agents. In this paper, we introduce RLzoo, a new DRL library that aims to make the development of DRL agents efficient. RLzoo provides developers with (i) high-level yet flexible APIs for prototyping DRL agents, and further customising the agents for best performance, (ii) a model zoo where users can import a wide range of DRL agents and easily compare their performance, and (iii) an algorithm that can automatically construct DRL agents with custom components (which are critical to improve agent’s perfor- mance in custom applications). Evaluation results show that RLzoo can effectively reduce the development cost of DRL agents, while achieving comparable performance with existing DRL libraries.","tags":["Machine Learning Systems"],"title":"Efficient Reinforcement Learning Development with RLzoo","type":"publication"},{"authors":["Yixiao Guo","Jiawei Liu","Guo Li","Luo Mai","Hao Dong"],"categories":null,"content":"","date":1628985600,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1628985600,"objectID":"93ea281c902a1b615b9dd5f4104e0318","permalink":"https://luomai.github.io/publication/2021-multimedia-hyperpose/","publishdate":"2020-08-15T00:00:00Z","relpermalink":"/publication/2021-multimedia-hyperpose/","section":"publication","summary":"Estimating human pose is an important yet challenging task in multimedia applications. Existing pose estimation libraries target reproducing standard pose estimation algorithms. When it comes to customising these algorithms for real-world applications, none of the existing libraries can offer both the flexibility of developing custom pose estimation algorithms and the high-performance of executing these algorithms on commodity devices. In this paper, we introduce HyperPose, a novel flexible and high-performance pose estimation library. HyperPose provides expressive Python APIs that enable developers to easily customise pose estimation algorithms for their applications. It further provides a model inference engine highly optimised for real-time pose estimation. This engine can dynamically dispatch carefully designed pose estimation tasks to CPUs and GPUs, thus automatically achieving high utilisation of hardware resources irrespective of deployment environments. Extensive evaluation results show that HyperPose can achieve up to 3.1x∼7.3x higher pose estimation throughput compared to state-of-the-art pose estimation libraries without compromising es- timation accuracy. By 2021, HyperPose has received over 1000 stars on GitHub and attracted users from both industry and academy.","tags":["Machine Learning Systems"],"title":"Fast and Flexible Human Pose Estimation with HyperPose","type":"publication"},{"authors":[],"categories":[],"content":"I am honored to give a lecture about AI/ML systems at the prestigious Oxford Machine Learning Summer School. The school covers some of the most important topics in ML/DL that the field is showing a growing interest in (e.g., Bayesian ML, representation learning, computer vision, natural language processing (NLP), reinforcement learning, causal ML, and transfer learning).\n","date":1627735555,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1627735555,"objectID":"b478305e04ee26d681b559febf06de9f","permalink":"https://luomai.github.io/post/21-oxfordml-news/","publishdate":"2021-07-31T13:45:55+01:00","relpermalink":"/post/21-oxfordml-news/","section":"post","summary":"I am honored to give a lecture about AI/ML systems at the prestigious Oxford Machine Learning Summer School. The school covers some of the most important topics in ML/DL that the field is showing a growing interest in (e.","tags":[],"title":"Invited lecture at the Oxford ML summer school","type":"post"},{"authors":[],"categories":[],"content":"I am excited to give talks about future AI/Data systems at TikTok, SenseTime, Tencent and SIGMOD Enterprise Database Workshop 2021.\n","date":1623329155,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1623329155,"objectID":"b79ca20ad9849911bfeb22a65feac61a","permalink":"https://luomai.github.io/post/21-summer-invited-talks-news/","publishdate":"2021-06-10T13:45:55+01:00","relpermalink":"/post/21-summer-invited-talks-news/","section":"post","summary":"I am excited to give talks about future AI/Data systems at TikTok, SenseTime, Tencent and SIGMOD Enterprise Database Workshop 2021.","tags":[],"title":"Invited talks at TikTok, SenseTime, Tencent and SIGMOD.","type":"post"},{"authors":["Luo Mai","Guo Li","Marcel Wagenlander","Konstantinos Fertakis","Andrei-Octavian Brabete","Peter Pietzuch"],"categories":null,"content":"","date":1606780800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1606780800,"objectID":"deb03b1b9dd9328c25abc6d179f08693","permalink":"https://luomai.github.io/publication/2020-osdi-kungfu/","publishdate":"2020-12-14T00:00:00Z","relpermalink":"/publication/2020-osdi-kungfu/","section":"publication","summary":" When using distributed machine learning (ML) systems to train models on a cluster of worker machines, users must configure a large number of parameters: hyper-parameters (e.g. the batch size and the learning rate) affect model convergence; system parameters (e.g. the number of workers and their communication topology) impact training performance. In current systems, adapting such parameters during training is ill-supported. Users must set system parameters at deployment time, and provide fixed adaptation schedules for hyper-parameters in the training program. We describe KungFu, a distributed ML library for Tensor- Flow that is designed to enable adaptive training. KungFu allows user to express high-level Adaptation Policies (APs) that describe how to change hyper- and system parameters during training. APs take real-time monitored metrics (e.g. signal-to-noise ratios and noise scale) as input and trigger control actions (e.g. cluster rescaling or updating the synchronisation strategy). For execution, APs are translated into monitoring and control operators, which are embedded in the dataflow graph. APs exploit an efficient asynchronous collective communication layer, which ensures concurrency and consistency of monitoring and adaptation operations.","tags":["Machine Learning Systems"],"title":"KungFu: Making Training in Distributed Machine Learning Adaptive","type":"publication"},{"authors":[],"categories":[],"content":"Our Paper \u0026ldquo;KungFu: Making Training in Distributed Machine Learning Adaptive\u0026rdquo; is accepted by USENIX Symposium on Operating Systems Design and Implementation (OSDI) 2020. OSDI is a highly selective flagship conference in computer science, especially on the topic of computer systems.\nOSDI brings together professionals from academic and industrial backgrounds in what has become a premier forum for discussing the design, implementation, and implications of systems software. The symposium emphasizes innovative research as well as quantified or insightful experiences in systems design and implementation.\n","date":1597754137,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1597754137,"objectID":"a29ffed6f8869959b067910c510c35e7","permalink":"https://luomai.github.io/post/20-kungfu-accept-news/","publishdate":"2020-08-18T13:35:37+01:00","relpermalink":"/post/20-kungfu-accept-news/","section":"post","summary":"Our Paper \u0026ldquo;KungFu: Making Training in Distributed Machine Learning Adaptive\u0026rdquo; is accepted by USENIX Symposium on Operating Systems Design and Implementation (OSDI) 2020. OSDI is a highly selective flagship conference in computer science, especially on the topic of computer systems.","tags":[],"title":"KungFu to appear at OSDI 2020","type":"post"},{"authors":[],"categories":[],"content":"Our Paper \u0026ldquo;Move Fast and Meet Deadlines: Fine-grained Real-time Stream Processing with Cameo\u0026rdquo; is accepted by USENIX Symposium on Networked Systems Design and Implementation (NSDI) 2021.\nNSDI focuses on the design principles, implementation, and practical evaluation of networked and distributed systems. Its goal is to bring together researchers from across the networking and systems community to foster a broad approach to addressing overlapping research challenges.\nNSDI provides a high-quality forum for presenting results and discussing ideas that further the knowledge and understanding of the networked systems community as a whole, continue a significant research dialog, or push the architectural boundaries of network services.\n","date":1593953155,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1593953155,"objectID":"f7b94a217973bf189234c6c48dc3baf8","permalink":"https://luomai.github.io/post/21-cameo-accept-news/","publishdate":"2020-07-05T13:45:55+01:00","relpermalink":"/post/21-cameo-accept-news/","section":"post","summary":"Our Paper \u0026ldquo;Move Fast and Meet Deadlines: Fine-grained Real-time Stream Processing with Cameo\u0026rdquo; is accepted by USENIX Symposium on Networked Systems Design and Implementation (NSDI) 2021.\nNSDI focuses on the design principles, implementation, and practical evaluation of networked and distributed systems.","tags":[],"title":"Cameo to appear at NSDI 2021","type":"post"},{"authors":null,"categories":null,"content":"Today\u0026rsquo;s machine learning systems must cope with growing complex models and increasingly complicated deployment environments, making them difficult to constantly deliver high performance with an empirical configuration. To address this, KungFu enables machine learning users to realise adaptive distributed training policies using high-level training monitoring and control APIs. KungFu has a fast and scalable runtime which can automatically scale out policy execution onto distributed GPU servers. Large-scale cluster experiments show that KungFu not only enables real-world adaptive training use cases, but also out-performs state-of-the-art distributed training systems including Horovod and Parameters Servers.\n","date":1590969600,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1590969600,"objectID":"511bc777d1f6350b91dcaec24c2cc6fb","permalink":"https://luomai.github.io/project/kungfu/","publishdate":"2020-06-01T00:00:00Z","relpermalink":"/project/kungfu/","section":"project","summary":"Adaptive Large-scale Deep Learning [![GitHub stars](https://img.shields.io/github/stars/lsds/kungfu.svg?style=social\u0026label=Star\u0026maxAge=2592000)](https://github.com/lsds/kungfu/stargazers/)","tags":null,"title":"KungFu","type":"project"},{"authors":["Marcel Wagenlander","Luo Mai","Guo Li","Peter Pietzuch"],"categories":null,"content":"","date":1590969600,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1590969600,"objectID":"f8af5e7249f7c40944769bd5268555f1","permalink":"https://luomai.github.io/publication/2020-hotcloud-spotnik/","publishdate":"2020-06-01T00:00:00Z","relpermalink":"/publication/2020-hotcloud-spotnik/","section":"publication","summary":"To achieve higher utilisation, cloud providers offer VMs with GPUs as lower-cost transient cloud resources. Transient VMs can be revoked at short notice and vary in their availability. This poses challenges to distributed machine learning (ML) jobs, which perform long-running stateful computation in which many workers maintain and synchronise model replicas. With transient VMs, existing systems either require a fixed number of reserved VMs or degrade performance when recovering from revoked transient VMs. We believe that future distributed ML systems must be de- signed from the ground up for transient cloud resources. This paper describes SPOTNIK, a system for training ML models that features a more adaptive design to accommodate transient VMs: (i) SPOTNIK uses an adaptive implementation of the all-reduce collective communication operation. As workers on transient VMs are revoked, SPOTNIK updates its membership and uses the all-reduce ring to recover; and (ii) SPOTNIK supports the adaptation of the synchronisation strategy between workers. This allows a training job to switch between different strategies in response to the revocation of transient VMs. Our experiments show that, after VM revocation, SPOTNIK recovers training within 300 ms for ResNet/ImageNet.","tags":["Machine Learning Systems","Cloud Computing"],"title":"Spotnik: Designing Distributed Machine Learning for Transient Cloud Resources","type":"publication"},{"authors":null,"categories":null,"content":"TensorLayer is a popular open-source TensorFlow-based deep learning and reinforcement library. It provides rich neural layers, pre-trained neural networks, data processing, model management and distributed training to facilitate the development of a wide spectrum of deep learning algorithms. TensorLayer has a transparent and flexible programming model, and thus suitable to customise deep neural networks for deployment and research purposes. It exhibits superior performance due to the low-cost integration with the TensorFlow backend. TensorLayer is easy to learn by providing massive tutorials, examples and real-world application codes. Since open-sourced in 2017, it has attracted more than 300,000 downloads, 6000 stars on Github, and 90 contributors around the world. TensorLayer is recently awarded the 2017 best open-source software by the prestigious ACM multimedia community.\n","date":1588291200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1588291200,"objectID":"802d61c9c8364c0f2a2655749425d54c","permalink":"https://luomai.github.io/project/tensorlayer/","publishdate":"2020-05-01T00:00:00Z","relpermalink":"/project/tensorlayer/","section":"project","summary":"Easy-to-use Deep Learning Library [![GitHub stars](https://img.shields.io/github/stars/tensorlayer/tensorlayer.svg?style=social\u0026label=Star\u0026maxAge=2592000)](https://github.com/tensorlayer/tensorlayer/stargazers/)","tags":null,"title":"TensorLayer","type":"project"},{"authors":null,"categories":null,"content":"Estimating human pose is a core task in many multimedia applications. To fully achieve its promise, users often need to customise pose estimation systems for best possible accuracy, and optimise the systems so that they can achieve real-time processing of high-resolution video streams. To meet these needs, we introduce HyperPose, a library for building pose estimation systems. HyperPose provides a large collection of high-level APIs to help users develop pose estimation algorithms that can achieve high accuracy in the wild. HyperPose further provides a high-performance algorithm execution engine. This engine has a high-performance dataflow for executing pose estimation algorithms. It dynamically dispatches dataflow operators onto CPUs/GPUs, which maximises hardware efficiency, thus achieving real-time processing. Evaluation result show that HyperPose allows users to declare many useful pose estimation algorithms. It also out-performs the performance of state-of-the-art pose estimation systems by up to 3.1x.\n","date":1585699200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1585699200,"objectID":"ed8e52ffeba07d28058b5554cd9c0009","permalink":"https://luomai.github.io/project/hyperpose/","publishdate":"2020-04-01T00:00:00Z","relpermalink":"/project/hyperpose/","section":"project","summary":"Real-time Visual Computing Library [![GitHub stars](https://img.shields.io/github/stars/tensorlayer/hyperpose.svg?style=social\u0026label=Star\u0026maxAge=2592000)](https://github.com/tensorlayer/hyperpose/stargazers/)","tags":null,"title":"HyperPose","type":"project"},{"authors":[],"categories":[],"content":"I am invited to give a talk: \u0026ldquo;Adaptive Distributed Training of Deep Learning Models\u0026rdquo; in the Workshop on AI Systems at ACM Symposium on Operating Systems Principles (SOSP) 2019.\n","date":1572958417,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1572958417,"objectID":"5968be8748bb244455614375d150f9a4","permalink":"https://luomai.github.io/post/19-talk-sosp/","publishdate":"2019-11-05T13:53:37+01:00","relpermalink":"/post/19-talk-sosp/","section":"post","summary":"I am invited to give a talk: \u0026ldquo;Adaptive Distributed Training of Deep Learning Models\u0026rdquo; in the Workshop on AI Systems at ACM Symposium on Operating Systems Principles (SOSP) 2019.","tags":[],"title":"Invited talk in the AI systems workshop at SOSP 2019","type":"post"},{"authors":[],"categories":null,"content":"","date":1572181200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1572181200,"objectID":"4e053c4645d288307aee6c84c1ac258f","permalink":"https://luomai.github.io/talk/2019-kungfu-sosp/","publishdate":"2019-10-27T13:00:00Z","relpermalink":"/talk/2019-kungfu-sosp/","section":"talk","summary":"Adaptive distributed training of deep learning models","tags":[],"title":"SOSP AI Systems Workshop","type":"talk"},{"authors":["Alexandros Koliousis","Pijika Watcharapichat","Matthias Weidlich","Luo Mai","Paolo Costa","Peter Pietzuch"],"categories":null,"content":"","date":1567296000,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1567296000,"objectID":"0ebdd56ec8701114a5aba1877375c187","permalink":"https://luomai.github.io/publication/2019-vldb-crossbow/","publishdate":"2019-09-01T00:00:00Z","relpermalink":"/publication/2019-vldb-crossbow/","section":"publication","summary":"Deep learning models are trained on servers with many GPUs, and training must scale with the number of GPUs. Systems such as TensorFlow and Caffe2 train models with parallel synchronous stochastic gradient descent: they process a batch of training data at a time, partitioned across GPUs, and average the resulting partial gradients to obtain an updated global model. To fully utilise all GPUs, systems must increase the batch size, which hinders statistical efficiency. Users tune hyper-parameters such as the learning rate to compensate for this, which is complex and model-specific. We describe Crossbow, a new single-server multi-GPU system for training deep learning models that enables users to freely choose their preferred batch size---however small---while scaling to multiple GPUs. Crossbow uses many parallel model replicas and avoids reduced statistical efficiency through a new synchronous training method. We introduce SMA, a synchronous variant of model averaging in which replicas independently explore the solution space with gradient descent, but adjust their search synchronously based on the trajectory of a globally-consistent average model. Crossbow achieves high hardware efficiency with small batch sizes by potentially training multiple model replicas per GPU, automatically tuning the number of replicas to maximise throughput. our experiments show that Crossbow improves the training time of deep learning models on an 8-GPU server by 1.3--4X compared to TensorFlow.","tags":["Machine Learning Systems"],"title":"CrossBow: Scaling Deep Learning with Small Batch Sizes on Multi-GPU Servers","type":"publication"},{"authors":null,"categories":null,"content":"Deep Reinforcement Learning (DRL) has become the foundation of many multimedia applications. To fully achieve its promise, multi-media users are looking for a library that allows them to efficiently design and test DRL agents and integrate the agents into their ap-plications. In this project, we introduce RLzoo, a novel DRL library that makes it easy to design, test and deploy DRL agents. RLzoo has high-level expressive APIs which enable its users to efficiently develop DRL agents. RLzoo users can leverage an automatic agent construction algorithm to seamlessly adopt custom agent modules,e.g., custom neural networks, which is the key for tuning agents for achieving the best possible performance. RLzoo users can access a large number of pre-implemented DRL environments and algorithms, making it a comprehensive DRL platform. On this platform,users can further easily manage and tune DRL agents through an interactive training terminal. Evaluation results show that: com-pared to existing DRL libraries, RLzoo not only achieves a high degree of abstraction in its API design. It also provides numerous useful DRL algorithms and environments which are not available in other libraries.\n","date":1567296000,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1567296000,"objectID":"c5967a74fd45d0f76d15d8220147f41b","permalink":"https://luomai.github.io/project/rlzoo/","publishdate":"2019-09-01T00:00:00Z","relpermalink":"/project/rlzoo/","section":"project","summary":"Reinforcement Learning Model Zoo [![GitHub stars](https://img.shields.io/github/stars/tensorlayer/rlzoo.svg?style=social\u0026label=Star\u0026maxAge=2592000)](https://github.com/tensorlayer/rlzoo/stargazers/)","tags":null,"title":"RLzoo","type":"project"},{"authors":null,"categories":null,"content":"Deep learning models are trained on servers with many GPUs, and training must scale with the number of GPUs. Systems such as TensorFlow and Caffe2 train models with parallel synchronous stochastic gradient descent: they process a batch of training data at a time, partitioned across GPUs, and average the resulting partial gradients to obtain an updated global model. To fully utilise all GPUs, systems must increase the batch size, which hinders statistical efficiency. Users tune hyper-parameters such as the learning rate to compensate for this, which is complex and model-specific. We introduce Crossbow, a new single-server multi-GPU system for training deep learning models that enables users to freely choose their preferred batch size\u0026mdash;however small\u0026mdash;while scaling to multiple GPUs. Crossbow uses many parallel model replicas and avoids reduced statistical efficiency through a new synchronous training method. We introduce SMA, a synchronous variant of model averaging in which replicas independently explore the solution space with gradient descent, but adjust their search synchronously based on the trajectory of a globally-consistent average model. Crossbow achieves high hardware efficiency with small batch sizes by potentially training multiple model replicas per GPU, automatically tuning the number of replicas to maximise throughput. our experiments show that Crossbow improves the training time of deep learning models on an 8-GPU server by 1.3\u0026ndash;4X compared to TensorFlow.\n","date":1561939200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1561939200,"objectID":"91604dd0ac0d85b19aabd81807a95340","permalink":"https://luomai.github.io/project/crossbow/","publishdate":"2019-07-01T00:00:00Z","relpermalink":"/project/crossbow/","section":"project","summary":"Deep Learning on Multi-GPU Servers [![GitHub stars](https://img.shields.io/github/stars/lsds/crossbow.svg?style=social\u0026label=Star\u0026maxAge=2592000)](https://github.com/lsds/crossbow/stargazers/)","tags":null,"title":"CrossBow","type":"project"},{"authors":["Luo Mai","Alexandros Koliousis","Guo Li","Andrei-Octavian Brabete","Peter Pietzuch"],"categories":null,"content":"","date":1561939200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1561939200,"objectID":"2b881ac3ec380aa87e2437d60162c356","permalink":"https://luomai.github.io/publication/2019-osr-review/","publishdate":"2019-07-01T00:00:00Z","relpermalink":"/publication/2019-osr-review/","section":"publication","summary":"Deep learning (DL) systems expose many tuning parameters (“hyper-parameters”) that affect the performance and accuracy of trained models. Increasingly users struggle to configure hyper-parameters, and a substantial portion of time is spent tuning them empirically. We argue that future DL systems should be designed to help manage hyper-parameters. We describe how a distributed DL system can (i) remove the impact of hyper-parameters on both performance and accuracy, thus making it easier to decide on a good setting, and (ii) support more powerful dynamic policies for adapting hyper-parameters, which take monitored training metrics into account. We report results from prototype implementations that show the practicality of DL system designs that are hyper-parameter-friendly.","tags":["Machine Learning Systems"],"title":"Taming Hyper-parameters in Deep Learning Systems","type":"publication"},{"authors":[],"categories":null,"content":"","date":1543669200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1543669200,"objectID":"5bdd4cabffc0f500301ba9c8fec2973a","permalink":"https://luomai.github.io/talk/2018-google-devfest/","publishdate":"2018-12-01T13:00:00Z","relpermalink":"/talk/2018-google-devfest/","section":"talk","summary":"TensorLayer: A flexible library for deep learning researchers and developers","tags":[],"title":"Google Developer Festival","type":"talk"},{"authors":["Luo Mai","Kai Zeng","Rahul Potharaju","Le Xu","Shivaram Venkataraman","Paolo Costa","Terry Kim","Saravanan Muthukrishnan","Vamsi Kuppa","Sudheer Dhulipalla","Sriram Rao"],"categories":null,"content":"","date":1530403200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1530403200,"objectID":"78143f48499166d71e098a960676c04d","permalink":"https://luomai.github.io/publication/2018-vldb-chi/","publishdate":"2018-07-01T00:00:00Z","relpermalink":"/publication/2018-vldb-chi/","section":"publication","summary":"Stream-processing workloads and modern shared cluster environments exhibit high variability and unpredictability. Combined with the large parameter space and the diverse set of user SLOs, this makes modern streaming systems very challenging to statically configure and tune. To address these issues, in this paper we investigate a novel control-plane design, Chi, which supports continuous monitoring and feedback, and enables dynamic re-configuration. Chi leverages the key insight of embedding control-plane messages in the data-plane channels to achieve a low-latency and flexible control plane for stream-processing systems. Chi introduces a new reactive programming model and design mechanisms to asynchronously execute control policies, thus avoiding global synchronization. We show how this allows us to easily implement a wide spectrum of control policies targeting different use cases observed in production. Large-scale experiments using production workloads from a popular cloud provider demonstrate the flexibility and efficiency of our approach.","tags":["Big Data Systems"],"title":"Chi: A Scalable and Programmable Control Plane for Distributed Stream Processing Systems","type":"publication"},{"authors":["Nik Sultana","Salvator Galea","David Greaves","Marcin Wojcik","Jonny Shipton","Richard Clegg","Luo Mai","Pietro Bressana","Robert Soule","Richard Mortier","Paolo Costa","Peter Pietzuch","Jon Crowcroft","Andrew W Moore","Noa Zilberman"],"categories":null,"content":"","date":1501545600,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1501545600,"objectID":"b5e6461c44a15dd286fce83f95e8aee2","permalink":"https://luomai.github.io/publication/2017-atc-emu/","publishdate":"2017-08-01T00:00:00Z","relpermalink":"/publication/2017-atc-emu/","section":"publication","summary":"Due to their performance and flexibility, FPGAs are an attractive platform for the execution of network functions. It has been a challenge for a long time though to make FPGA programming accessible to a large audience of developers. An appealing solution is to compile code from a general-purpose language to hardware using high-level synthesis. Unfortunately, current approaches to implement rich network functionality are insufficient because they lack: (i) libraries with abstractions for common network operations and data structures, (ii) bindings to the underlying “substrate” on the FPGA, and (iii) debugging and profiling support. This paper describes Emu, a new standard library for an FPGA hardware compiler that enables developers to rapidly create and deploy network functionality. Emu allows for high-performance designs without being bound to particular packet processing paradigms. Furthermore, it supports running the same programs on CPUs, in Mininet, and on FPGAs, providing a better development environment that includes advanced debugging capabilities. We demonstrate that network functions implemented using Emu have only negligible resource and performance overheads compared with natively-written hardware versions.","tags":["Data Centre Networks"],"title":"Emu: Rapid Prototyping of Networking Services","type":"publication"},{"authors":["Hao Dong","Akara Supratak","Luo Mai","Fangde Liu","Axel Oehmichen","Simiao Yu","Yike Guo"],"categories":null,"content":"","date":1498867200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1498867200,"objectID":"df83558d9fa95a003b3db9795ca5abf2","permalink":"https://luomai.github.io/publication/2017-multimedia-tensorlayer/","publishdate":"2017-07-01T00:00:00Z","relpermalink":"/publication/2017-multimedia-tensorlayer/","section":"publication","summary":"Recently we have observed emerging uses of deep learning techniques in multimedia systems. Developing a practical deep learning system is arduous and complex. It involves labor-intensive tasks for constructing sophisticated neural networks, coordinating multiple network models, and managing a large amount of training-related data. To facilitate such a development process, we propose TensorLayer which is a Python-based versatile deep learning library. TensorLayer provides high-level modules that abstract sophisticated operations towards neuron layers, network models, training data and dependent training jobs. In spite of offering simplicity, it has transparent module interfaces that allows developers to flexibly embed low-level controls within a backend engine, with the aim of supporting fine-grain tuning towards training. Real-world cluster experiment results show that TensorLayeris able to achieve competitive performance and scalability in critical deep learning tasks. TensorLayer was released in September 2016 on GitHub. Since after, it soon become one of the most popular open-sourced deep learning library used by researchers and practitioners.","tags":["Machine Learning Systems"],"title":"TensorLayer: A Versatile Library for Efficient Deep Learning Development","type":"publication"},{"authors":["Abdul Alim","Richard G. Clegg","Luo Mai","Lukas Rupprecht","Eric Seckler","Paolo Costa","Peter Pietzuch","Alexander L. Wolf","Nik Sultana","Jon Crowcroft","Anil Madhavapeddy","Andrew Moore","Richard Mortier","Luis Oviedo","Masoud Koleni","Derek McAuley","Matteo Migliavacca"],"categories":null,"content":"","date":1470009600,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1470009600,"objectID":"7cfc2cbb955075a97335eab5c7c29dd6","permalink":"https://luomai.github.io/publication/2016-atc-flick/","publishdate":"2016-08-01T00:00:00Z","relpermalink":"/publication/2016-atc-flick/","section":"publication","summary":"Data centre networks are increasingly programmable, with application-specific network services proliferating, from custom load-balancers to middleboxes providing caching and aggregation. Developers must currently implement these services using traditional low-level APIs, which neither support natural operations on application data nor provide efficient performance isolation. We describe FLICK, a framework for the programming and execution of application-specific network services on multi-core CPUs. Developers write network services in the FLICK language, which offers high-level processing constructs and application-relevant data types. FLICK programs are translated automatically to efficient, parallel task graphs, implemented in C++ on top of a user-space TCP stack. Task graphs have bounded resource usage at runtime, which means that the graphs of multiple services can execute concurrently without interference using cooperative scheduling. We evaluate FLICK with several services (an HTTP load-balancer, a Memcached router and a Hadoop data aggregator), showing that it achieves good performance while reducing development effort.","tags":["Data Centre Networks","Big Data Systems"],"title":"Flick: Developing and Running Application-specific Network Services ","type":"publication"},{"authors":["Da Yu","Luo Mai","Somaya Arianfar","Rodrigo Fonseca","Orran Krieger","David Oran"],"categories":null,"content":"","date":1467331200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1467331200,"objectID":"8c76da1be60380cb77551e9aa9ddd7cd","permalink":"https://luomai.github.io/publication/2016-hotcloud-netex/","publishdate":"2016-07-01T00:00:00Z","relpermalink":"/publication/2016-hotcloud-netex/","section":"publication","summary":"Virtually all public clouds today are run by single providers, and this creates near-monopolies, inefficient markets, and hinders innovation at the infrastructure level. There are current proposals to change this, by creating open architectures that allow providers of computing and storage resources to compete for tenant services at multiple levels, all the way down to the bare metal. Networking, however, is not part of this, and is viewed as a commodity much like power or cooling. In this paper we borrow ideas from the Internet architecture, and propose to structure the cloud datacenter network as a marketplace where multiple service providers can offer connectivity services to tenants. Our marketplace, NetEx, divides the network into independently managed pods of resources, interconnected with multiple providers through special programmable switches that play a role analogous to that of an IXP. We demonstrate the feasibility of such an architecture by a prototype in Mininet, and argue that this can be a way to provide innovation, competition, and efficiency in future cloud datacenter networks.","tags":["Cloud Computing"],"title":"Towards a Network Marketplace in a Cloud","type":"publication"},{"authors":["Luo Mai","Chuntao Hong","Paolo Costa"],"categories":null,"content":"","date":1435708800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1435708800,"objectID":"b9af09566036effe01693fbd7417c92a","permalink":"https://luomai.github.io/publication/2015-hotcloud-mlnet/","publishdate":"2015-07-01T00:00:00Z","relpermalink":"/publication/2015-hotcloud-mlnet/","section":"publication","summary":"To cope with the ever growing availability of training data, there have been several proposals to scale machine learning computation beyond a single server and distribute it across a cluster. While this enables reducing the training time, the observed speed up is often limited by network bottlenecks. To address this, we design MLNET, a host-based communication layer that aims to improve the network performance of distributed machine learning systems. This is achieved through a combination of traffic reduction techniques (to diminish network load in the core and at the edges) and traffic management (to reduce average training time). A key feature of MLNET is its compatibility with existing hardware and software infrastructure so it can be immediately deployed. We describe the main techniques underpinning ML- NET and show through simulation that the overall training time can be reduced by up to 78%. While preliminary, our results indicate the critical role played by the network and the benefits of introducing a new communication layer to increase the performance of distributed machine learning systems.","tags":["Machine Learning Systems"],"title":"Optimizing Network Performance in Distributed Machine Learning","type":"publication"},{"authors":["Luo Mai","Lukas Rupprecht","Abdul Alim","Paolo Costa","Matteo Migliavacca","Peter Pietzuch","Alexander L. Wolf"],"categories":null,"content":"","date":1417392000,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1417392000,"objectID":"b5afacccb120fcc5840643a1cfe54989","permalink":"https://luomai.github.io/publication/2014-conext-netagg/","publishdate":"2014-12-01T00:00:00Z","relpermalink":"/publication/2014-conext-netagg/","section":"publication","summary":"Data centre applications for batch processing (e.g. map/reduce frameworks) and online services (e.g. search engines) scale by distributing data and computation across many servers. They typically follow a partition/aggregation pattern: tasks are first partitioned across servers that process data locally, and then those partial results are aggregated. This data aggregation step, however, shifts the performance bottleneck to the network, which typically struggles to support many-to-few, high-bandwidth traffic between servers. Instead of performing data aggregation at edge servers, we show that it can be done more efficiently along network paths. We describe NETAGG, a software platform that supports on-path aggregation for network-bound partition/aggregation applications. NET-AGG exploits a middlebox-like design, in which dedicated servers (agg boxes) are connected by high-bandwidth links to network switches. Agg boxes execute aggregation functions provided by ap- plications, which alleviates network hotspots because only a fraction of the incoming traffic is forwarded at each hop. NETAGG requires only minimal application changes: it uses shim layers on edge servers to redirect application traffic transparently to the agg boxes. Our experimental results show that NETAGG improves substantially the throughput of two sample applications, the Solr distributed search engine and the Hadoop batch processing framework. Its design allows for incremental deployment in existing data centres and incurs only a modest investment cost.","tags":["Data Centre Networks","Big Data Systems"],"title":"NetAgg: Using Middleboxes for Application-specific On-path Aggregation in Data Centres","type":"publication"},{"authors":["Luo Mai","Evangelia Kalyvianaki","Paolo Costa"],"categories":null,"content":"","date":1385856000,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1385856000,"objectID":"9221ab2bfeabe9c6199812e0827c0b25","permalink":"https://luomai.github.io/publication/2013-ladis-mai/","publishdate":"2013-12-01T00:00:00Z","relpermalink":"/publication/2013-ladis-mai/","section":"publication","summary":"Existing cloud provisioning schemes allocate re- sources to batch processing systems at deployment time and only change this allocation at run-time due to unexpected events such as server failures. We observe that MapReduce-like jobs are time- malleable, i.e., at runtime it is possible to dynamically vary the number of resources allocated to a job and, hence, its completion time. In this paper, we propose a novel approach based on time-malleability to opportunistically update job resources in order to increase overall utilization and revenue. To set the right incentives for both providers and tenants, we introduce a novel pricing model that charges tenants according to job completion times. Using this model, we formulate an optimization problem for revenue maximization. Preliminary results show that compared to today’s practices our solution can increase revenue by up to 69.7% and can accept up to 57% more jobs.","tags":["Cloud Computing"],"title":"Exploiting Time-malleability in Cloud-based Batch Processing Systems","type":"publication"},{"authors":["Luo Mai","Longfei Shangguan","Chao Lang","Junzhao Du","Zhenjiang Li","Mo Li"],"categories":null,"content":"","date":1322697600,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1322697600,"objectID":"a13bae634b4f93dcf87a1cea80752334","permalink":"https://luomai.github.io/publication/2011-mass-mai/","publishdate":"2011-12-01T00:00:00Z","relpermalink":"/publication/2011-mass-mai/","section":"publication","summary":"We study the rendezvous data collection problem for the mobile sink in wireless sensor networks. We introduce to jointly optimize trajectory planning for the mobile sink and workload balancing for the network. By doing so, the mobile sink is able to efficiently collect network-wide data within a given delay bound and the network can eliminate the energy bottleneck to dramatically prolong its lifetime. Such a joint optimization problem is shown to be NP-hard and we propose an approximation algorithm, named RPS-LB, to approach the optimal solution. In RPS-LB, according to observed properties of the median reference structure in the network, a series of Rendezvous Points (RPs) are selected to construct the trajectory for the mobile sink and the derived approximation ratio of RPS- LB guarantees that the formed trajectory is comparable with the optimal solution. The workload allocated to each RP is proven to be balanced mathematically. We then relax the assumption that mobile sink knows the location of each sensor node and present a localized, fully distributed version, RPS-LB-D, which largely improves the system applicability in practice. We verify the effectiveness of our proposals via extensive experiments.","tags":["Mobile Computing"],"title":"Load Balanced Rendezvous Data Collection in Wireless Sensor Networks","type":"publication"}]